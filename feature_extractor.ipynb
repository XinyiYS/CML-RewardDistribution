{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from collections import OrderedDict\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from data.pipeline import get_data_raw\n",
    "from core.kernel import get_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomView(nn.Module):  # Flattening layer for nn.Sequential\n",
    "    def __init__(self, shape):\n",
    "        super(CustomView, self).__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(*self.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitAutoEncoder(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    LitAutoEncoder(\n",
    "      (encoder): ...\n",
    "      (decoder): ...\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_channels, side_dim, hidden_dim, lr, gamma):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv2d(in_channels=num_channels, out_channels=64, kernel_size=5, stride=2, padding=2)),\n",
    "            ('lrelu1', nn.LeakyReLU()),\n",
    "            ('bn1', nn.BatchNorm2d(64)),\n",
    "            ('conv2', nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, stride=2, padding=2)),\n",
    "            ('lrelu2', nn.LeakyReLU()),\n",
    "            ('bn2', nn.BatchNorm2d(128)),\n",
    "            ('conv3', nn.Conv2d(in_channels=128, out_channels=256, kernel_size=5, stride=2, padding=2)),\n",
    "            ('lrelu3', nn.LeakyReLU()),\n",
    "            ('bn3', nn.BatchNorm2d(256)),\n",
    "            ('conv4', nn.Conv2d(in_channels=256, out_channels=512, kernel_size=5, stride=2, padding=2)),\n",
    "            ('lrelu4', nn.LeakyReLU()),\n",
    "            ('bn4', nn.BatchNorm2d(512)),\n",
    "            ('view1', CustomView((-1, 2048))),\n",
    "            ('linear1', nn.Linear(2048, hidden_dim))\n",
    "        ]))\n",
    "\n",
    "        self.decoder = nn.Sequential(OrderedDict([\n",
    "            ('linear1', nn.Linear(hidden_dim, 2048)),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('bn1', nn.BatchNorm1d(2048)),\n",
    "            ('view1', CustomView((-1, 512, 2, 2))),\n",
    "            ('convT1', nn.ConvTranspose2d(512, 256, kernel_size=5, stride=2, padding=2, output_padding=1)),\n",
    "            ('relu2', nn.ReLU()),\n",
    "            ('bn2', nn.BatchNorm2d(256)),\n",
    "            ('convT2', nn.ConvTranspose2d(256, 128, kernel_size=5, stride=2, padding=2,\n",
    "                               output_padding=0 if side_dim == 28 else 1)),\n",
    "            ('relu3', nn.ReLU()),\n",
    "            ('bn3', nn.BatchNorm2d(128)),\n",
    "            ('convT3', nn.ConvTranspose2d(128, 64, kernel_size=5, stride=2, padding=2, output_padding=1)),\n",
    "            ('relu4', nn.ReLU()),\n",
    "            ('bn4', nn.BatchNorm2d(64)),\n",
    "            ('convT4', nn.ConvTranspose2d(64, num_channels, kernel_size=5, stride=2, padding=2, output_padding=1)),\n",
    "            ('tanh1', nn.Tanh())\n",
    "        ]))\n",
    "\n",
    "        self.kernel = get_kernel('rq', hidden_dim)\n",
    "        self.lr = lr\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, x):\n",
    "        # in lightning, forward defines the prediction/inference actions\n",
    "        embedding = self.encoder(x)\n",
    "        return embedding\n",
    "\n",
    "    def autoencoder_loss(self, dataset):\n",
    "        x, y = dataset\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        return F.mse_loss(x_hat, x)\n",
    "\n",
    "    def mmd_loss(self, p, q):\n",
    "        x_p, y_p = p\n",
    "        x_q, y_q = q\n",
    "        z_p = self.encoder(x_p)\n",
    "        z_q = self.encoder(x_q)\n",
    "        return mmd_neg_unbiased(z_p, z_q, self.kernel)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        ae_loss = 0\n",
    "        # Autoencoder loss\n",
    "        for dataset in batch[:-1]:\n",
    "            ae_loss += self.autoencoder_loss(dataset)\n",
    "\n",
    "        mmd_loss = 0\n",
    "        # MMD loss, parties against reference dataset (all parties + candidates)\n",
    "        ref_dataset = batch[-1]\n",
    "        for dataset in batch[:-2]:\n",
    "            mmd_loss += self.gamma * self.mmd_loss(dataset, ref_dataset)\n",
    "\n",
    "        loss = ae_loss + mmd_loss\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        ae_loss = 0\n",
    "        for dataset in batch[:-1]:\n",
    "            ae_loss += self.autoencoder_loss(dataset)\n",
    "        self.log('autoencoder_loss', ae_loss)\n",
    "\n",
    "        mmd_loss = 0\n",
    "        ref_dataset = batch[-1]\n",
    "        for dataset in batch[:-2]:\n",
    "            mmd_loss += self.mmd_loss(dataset, ref_dataset)\n",
    "        self.log('mmd_loss', mmd_loss)\n",
    "\n",
    "        self.log('total_loss', ae_loss + mmd_loss)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'mnist'\n",
    "split = 'unequal'\n",
    "num_channels = 1\n",
    "side_dim = 28\n",
    "hidden_dim = 16\n",
    "gamma = '005'\n",
    "party_data_size = 10000\n",
    "candidate_data_size = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = LitAutoEncoder.load_from_checkpoint(\"models/{}-{}-gamma{}.ckpt\".format(dataset, split, gamma),\n",
    "                                           num_channels=num_channels,\n",
    "                                           side_dim=side_dim,\n",
    "                                           hidden_dim=hidden_dim,\n",
    "                                           lr=0.001,\n",
    "                                           gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_datasets, party_labels, candidate_dataset, candidate_labels = get_data_raw(dataset=dataset,\n",
    "                                                                                 num_classes=10,\n",
    "                                                                                 party_data_size=party_data_size,\n",
    "                                                                                 candidate_data_size=candidate_data_size,\n",
    "                                                                                 split=split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(model, data, hidden_dim, batch_size=256):\n",
    "    # data now is in format NHWC, model requires NCHW\n",
    "    n = len(data)\n",
    "    data = torch.tensor(np.transpose(data, [0, 3, 1, 2]))\n",
    "    features = np.zeros((n, hidden_dim))\n",
    "    for i in range(int(np.ceil(n / batch_size))):\n",
    "        start = i * batch_size\n",
    "        end = (i+1) * batch_size\n",
    "        features[start:end] = model.encoder(data[start:end]).detach().numpy()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = get_features(model, candidate_dataset, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_features = np.array([get_features(model, data, hidden_dim) for data in party_datasets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_features = get_features(model, candidate_dataset, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(open(\"data/{}/{}-gamma{}-party_features.npy\".format(dataset, split, gamma), \"wb\"), party_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(open(\"data/{}/{}-gamma{}-party_labels.npy\".format(dataset, split, gamma), \"wb\"), party_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(open(\"data/{}/{}-gamma{}-cand_features.npy\".format(dataset, split, gamma), \"wb\"), candidate_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(open(\"data/{}/{}-gamma{}-cand_labels.npy\".format(dataset, split, gamma), \"wb\"), candidate_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
