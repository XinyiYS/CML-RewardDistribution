{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import torch\n",
    "import gpytorch\n",
    "from tqdm.notebook import trange\n",
    "import heapq\n",
    "import math\n",
    "import pickle\n",
    "from algorithms.cd import con_div\n",
    "from algorithms.ccr import con_conv_rate\n",
    "from utils.class_imbalance import get_classes, class_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_GMM(means, covs, num_samples):\n",
    "    \"\"\"\n",
    "    Samples equally from clusters of normal distributions.\n",
    "    \"\"\"\n",
    "    assert(means.shape[0] == covs.shape[0])\n",
    "    assert(means.shape[1] == covs.shape[1])\n",
    "    assert(covs.shape[1] == covs.shape[2])\n",
    "    \n",
    "    n = means.shape[0]\n",
    "    d = means.shape[1]\n",
    "    samples = np.zeros((num_samples, d))\n",
    "    clusters = np.zeros(num_samples, dtype=np.int32)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        cluster = np.random.randint(n)\n",
    "        samples[i] = np.random.multivariate_normal(means[cluster], covs[cluster], check_valid='raise')\n",
    "        clusters[i] = cluster\n",
    "    \n",
    "    return samples, clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 5\n",
    "d = 2\n",
    "num_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.random.uniform(size=(num_clusters, d))\n",
    "covs = np.zeros((num_clusters, d, d))\n",
    "for i in range(num_clusters):\n",
    "    covs[i] = np.eye(d)/200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sets = np.zeros((num_clusters, num_samples, d))\n",
    "test_sets = np.zeros((num_clusters, num_samples, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_clusters):\n",
    "    train_sets[i] = np.random.multivariate_normal(means[i], covs[i], size=(num_samples), check_valid='raise')\n",
    "    test_sets[i] = np.random.multivariate_normal(means[i], covs[i], size=(num_samples), check_valid='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.mmd import perm_sampling, mmd\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_mmd_biased(X, Y, k):\n",
    "    \"\"\"\n",
    "    Calculates biased MMD^2. A, B and C are the pairwise-XX, pairwise-XY, pairwise-YY summation terms respectively.\n",
    "    :param X: array of shape (n, d)\n",
    "    :param Y: array of shape (m, d)\n",
    "    :param k: GPyTorch kernel\n",
    "    :return: MMD^2, A, B, C\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    m = Y.shape[0]\n",
    "    X_tens = torch.tensor(X, dtype=torch.float32)\n",
    "    Y_tens = torch.tensor(Y, dtype=torch.float32)\n",
    "\n",
    "    A = (1 / (n ** 2)) * torch.sum(k(X_tens).evaluate())\n",
    "    B = -(2 / (n * m)) * torch.sum(k(X_tens, Y_tens).evaluate())\n",
    "    C = (1 / (m ** 2)) * torch.sum(k(Y_tens).evaluate())\n",
    "\n",
    "    return -(A + B).item(), -A.item(), -B.item(), -C.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perm_sampling_neg_biased(P, Q, k, num_perms=200, eta=1.0):\n",
    "    \"\"\"\n",
    "    Shuffles two datasets together, splits this mix in 2, then calculates MMD to simulate P=Q. Does this num_perms\n",
    "    number of times.\n",
    "    :param P: First dataset, array of shape (n, d)\n",
    "    :param Q: Second dataset, array of shape (m, d)\n",
    "    :param k: GPyTorch kernel\n",
    "    :param num_perms: Number of permutations done to get range of MMD values.\n",
    "    :param eta: Fraction of samples taken in each shuffle. The larger this parameter, the smaller the variance in the estimate. Defaults\n",
    "    to 0.5*(n+m)\n",
    "    :return: Sorted list of MMD values.\n",
    "    \"\"\"\n",
    "    mmds = []\n",
    "    num_samples = int(eta * (P.shape[0] + Q.shape[0]) // 2)\n",
    "    XY = np.concatenate((P, Q))\n",
    "\n",
    "    for _ in trange(num_perms, desc=\"Permutation sampling\"):\n",
    "        p = np.random.permutation(len(XY))\n",
    "        X = XY[p[:num_samples]]\n",
    "        Y = XY[p[num_samples:num_samples*2]]\n",
    "        mmds.append(neg_mmd_biased(X, Y, k)[0])\n",
    "    return sorted(mmds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_candidate_points = 10000\n",
    "num_parties = 10\n",
    "\n",
    "gmm_clusters = [sample_GMM(means, covs, num_candidate_points) for i in range(num_clusters)]\n",
    "X = gmm_clusters[0][0]\n",
    "Y = gmm_clusters[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=d))\n",
    "kernel.base_kernel.lengthscale = [1, 1]\n",
    "kernel.outputscale = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "neg_mmd_biased(test_sets[1], test_sets[1], kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "neg_mmd_biased(test_sets[1][:100], test_sets[1][:100], kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_mmd_biased(test_sets[0], test_sets[1], kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_etas = np.linspace(np.log(0.025), np.log(1.), 10)\n",
    "etas = np.exp(log_etas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "etas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_samps = []\n",
    "for eta in etas:\n",
    "    samps = perm_sampling_neg_biased(X[:4000], Y[:4000], kernel, num_perms=1000, eta=eta)\n",
    "    all_samps.append(samps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_samps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samps_untruncated = all_samps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samps = []\n",
    "for samp in all_samps_untruncated:\n",
    "    new_samp = []\n",
    "    for val in samp:\n",
    "        if val <= 0.9425499439239502:\n",
    "            new_samp.append(val)\n",
    "    all_samps.append(new_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_curves = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(all_samps, open(\"all_samps.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_x = []\n",
    "all_density = []\n",
    "for i in range(num_curves):\n",
    "    bins = np.histogram(all_samps[i], bins=50)[1]\n",
    "    interval = bins[1] - bins[0]\n",
    "    bins = np.concatenate(([bins[0] - interval*i for i in range(700, 0, -1)], bins))\n",
    "    density = stats.gaussian_kde(all_samps[i])\n",
    "    n, x, _ = plt.hist(all_samps[0], bins=bins, \n",
    "                   histtype=u'step', density=True)  \n",
    "    all_x.append(x)\n",
    "    all_density.append(density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(all_x, open(\"all_x.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_x[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_density[6](0.936)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etas[6] = 0.292"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6), dpi=300)\n",
    "plt.title(\"Effect of $\\eta$ on variance of $\\widehat{MMD}^2$ distribution\")\n",
    "\n",
    "for i in range(num_curves):\n",
    "    if i in [0, 6, 9]:\n",
    "        x = all_x[i]\n",
    "        density = all_density[i]\n",
    "        plt.plot([0] + x, density(x), label=\"$\\eta = {}$\".format(etas[i]), color=cm.get_cmap('Spectral')(i*0.1), linewidth=2)\n",
    "        plt.legend()\n",
    "        plt.ylabel(\"Unnormalized density\")\n",
    "        plt.xlabel(\"$v(X)$\")\n",
    "        plt.xlim(left=0.9325, right=0.9425499439239502)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neg_mmd_biased(X[:4000], Y[:4000], kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "neg_mmd_biased(test_sets[0], test_sets[1], kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "neg_mmd_biased(test_sets[1], test_sets[1], kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "neg_mmd_biased(test_sets[1][:100], test_sets[1], kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_mmd_biased(X, Y, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_mmd_biased(X[:1000], Y[:1000], kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_mmd_biased(Y[:1000], Y[:1000], kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd(X[:1000], Y[:1000], kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd(Y[1000], Y[], kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[0.2, 0.2, 0.2, 0.2, 0.2],\n",
    " [0.2, 0.2, 0.2, 0.2, 0.2],\n",
    " [0.6, 0.4, 0.0, 0.0, 0.0],\n",
    " [0.0, 0.2, 0.6, 0.2, 0.0],\n",
    " [0.0, 0.0, 0.0, 0.4, 0.6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol = np.array([[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
    "                [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
    "                [0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(lol, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
