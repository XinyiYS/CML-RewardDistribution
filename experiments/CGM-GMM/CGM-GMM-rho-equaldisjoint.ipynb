{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import torch\n",
    "import gpytorch\n",
    "from tqdm.notebook import trange\n",
    "import heapq\n",
    "import math\n",
    "import pickle\n",
    "import itertools\n",
    "from utils.class_imbalance import get_classes, class_proportion\n",
    "\n",
    "from algorithms.cgm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sample_GMM(means, covs, num_samples):\n",
    "    \"\"\"\n",
    "    Samples equally from clusters of normal distributions.\n",
    "    \"\"\"\n",
    "    assert(means.shape[0] == covs.shape[0])\n",
    "    assert(means.shape[1] == covs.shape[1])\n",
    "    assert(covs.shape[1] == covs.shape[2])\n",
    "    \n",
    "    n = means.shape[0]\n",
    "    d = means.shape[1]\n",
    "    samples = np.zeros((num_samples, d))\n",
    "    clusters = np.zeros(num_samples, dtype=np.int32)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        cluster = np.random.randint(n)\n",
    "        samples[i] = np.random.multivariate_normal(means[cluster], covs[cluster], check_valid='raise')\n",
    "        clusters[i] = cluster\n",
    "    \n",
    "    return samples, clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_clusters = 5\n",
    "d = 2\n",
    "num_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "means = np.random.uniform(size=(num_clusters, d))\n",
    "covs = np.zeros((num_clusters, d, d))\n",
    "for i in range(num_clusters):\n",
    "    covs[i] = np.eye(d)/200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_sets = np.zeros((num_clusters, num_samples, d))\n",
    "test_sets = np.zeros((num_clusters, num_samples, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(num_clusters):\n",
    "    train_sets[i] = np.random.multivariate_normal(means[i], covs[i], size=(num_samples), check_valid='raise')\n",
    "    test_sets[i] = np.random.multivariate_normal(means[i], covs[i], size=(num_samples), check_valid='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6), dpi=300)\n",
    "for i in range(num_clusters):\n",
    "    plt.scatter(train_sets[i, :, 0], train_sets[i, :, 1], s=2, color=cm.get_cmap('Set1')(i*(1/9)), label=\"{0}\".format(i))\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equal disjoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_parties = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disjoint_prop = np.eye(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "party_datasets = split_proportions(train_sets, disjoint_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "plt.figure(figsize=(10, 6), dpi=300)\n",
    "plt.xlim(0, 0.8)\n",
    "plt.ylim(-0.2, 1.0)\n",
    "for i in range(num_parties):\n",
    "    if i == 4:\n",
    "        plt.scatter(party_datasets[i, :, 0], party_datasets[i, :, 1], s=2, color=cm.get_cmap('Set1')(i*(1/9)), label=\"{0}\".format(i))\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=d))\n",
    "kernel.base_kernel.lengthscale = [0.5, 0.5]\n",
    "kernel.outputscale = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference_dataset, reference_labels = sample_GMM(means, covs, num_samples=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perm_samp_dataset, perm_samp_labels = sample_GMM(means, covs, num_samples=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_samp_dataset = np.concatenate(party_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_dataset = np.concatenate(party_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = get_v(party_datasets, reference_dataset, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "phi = shapley(v, num_parties)\n",
    "print(phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alpha = norm(phi)\n",
    "print(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1e-03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# etas = [0.001, 0.01, 0.1, 0.25, 0.5]\n",
    "# all_sorted_vX = []\n",
    "# for eta in etas:\n",
    "#     sorted_vX = perm_sampling_neg_biased(perm_samp_dataset, reference_dataset, kernel, num_perms=200, eta=eta)\n",
    "#     all_sorted_vX.append(sorted_vX)\n",
    "#     print(\"Eta = {} - Mean:{} \\\\ Median:{} \\\\ Min: {} \\\\ Max: {}\".format(eta, np.mean(sorted_vX), np.median(sorted_vX), np.min(sorted_vX), np.max(sorted_vX)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_sorted_vX_variant = []\n",
    "# for eta in etas:\n",
    "#     sorted_vX = perm_sampling_neg_biased_variant(perm_samp_dataset, reference_dataset, kernel, num_perms=200, eta=eta)\n",
    "#     all_sorted_vX_variant.append(sorted_vX)\n",
    "#     print(\"Eta = {} - Mean:{} \\\\ Median:{} \\\\ Min: {} \\\\ Max: {}\".format(eta, np.mean(sorted_vX), np.median(sorted_vX), np.min(sorted_vX), np.max(sorted_vX)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vN = get_vN(v, num_parties)\n",
    "print(vN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v_is = get_v_is(v, num_parties)\n",
    "print(v_is)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q, rho = get_q_rho(alpha, v_is, vN, phi, v, cond=\"R6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v_is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all condition\n",
    "r = list(map(q, alpha))\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_candidate_points = 8000\n",
    "gmm_clusters = [sample_GMM(means, covs, num_candidate_points) for i in range(num_clusters)]\n",
    "gmm = np.array([pair[0] for pair in gmm_clusters])\n",
    "clusters = np.array([pair[1] for pair in gmm_clusters])\n",
    "cand_datasets = np.array([gmm[0]]*num_parties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greeds = np.ones(num_parties) * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rewards, deltas, mus = reward_realization(cand_datasets, \n",
    "                                          reference_dataset, \n",
    "                                          r, \n",
    "                                          party_datasets, \n",
    "                                          kernel, \n",
    "                                          greeds=greeds,\n",
    "                                          rel_tol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.delete(x, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump((gmm, clusters, reference_dataset, cand_datasets, party_datasets, greeds, rewards, deltas, mus), open(\"results/CGM-GMM-rho-equaldisjoint-greed3-stable.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_props = []\n",
    "for result in rewards:\n",
    "        class_props.append(class_proportion(get_classes(np.array(result), gmm[0], clusters[0]), num_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_parties):\n",
    "    print(mmd_neg_biased(np.concatenate([party_datasets[i], np.array(rewards[i])], axis=0), reference_dataset, kernel)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
